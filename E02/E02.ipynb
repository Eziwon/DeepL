{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8006a4a5-1268-4ba0-98e5-65287103f8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f03a06f-81dd-4302-98cf-d37f2087fbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the version of pytorch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350539ee-5b89-4cbe-9772-4fbae2aafd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format='retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b070f51-06f4-42c2-950d-a4a118dfa7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the random seed\n",
    "torch.manual_seed(316)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e40d34c-1253-42b3-8610-87a604d12169",
   "metadata": {},
   "source": [
    "# 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e41fae3-eb4f-4fe1-9b29-19e3a64ff0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define transform for train, valid\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75cb75c-838c-4367-ae72-886ec58a9eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the dataset\n",
    "dataset = datasets.MNIST('.', download=True, train=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ce806d-6498-40da-af19-c62b90089726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the length of dataset\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1a9177-f251-4a5e-98d0-cd76ace0d28a",
   "metadata": {},
   "source": [
    "## 1-1. Split the data into training set and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e6aadf-0dd8-484b-90d9-08389d5b8655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split\n",
    "len_trainset = int(len(dataset) * 0.8)\n",
    "len_valset = len(dataset) - len_trainset\n",
    "\n",
    "trainset, valset = torch.utils.data.random_split(dataset, [len_trainset, len_valset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed930e82-a5ae-455f-a377-b9709ff1e1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the dataset size for training and validation\n",
    "print(len(trainset))\n",
    "print(len(valset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616570bc-44a2-49f4-af98-7f65e47dd524",
   "metadata": {},
   "source": [
    "## 1-2. Training set & Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28eeee7b-fcd9-4cf0-b41e-16677f8a7e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the batch size as 32\n",
    "batch_size = 32\n",
    "\n",
    "# loader for the training set\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# loader for the validation set\n",
    "valloader = torch.utils.data.DataLoader(\n",
    "    valset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699ce435-2b6d-42a3-afaf-69bacfbdac28",
   "metadata": {},
   "source": [
    "# 2. Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466f295e-1aae-49ba-ae46-30e373e80d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a first batch\n",
    "images, labels = next(iter(trainloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76cab005-8073-4f35-8ba5-8f5777b48e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the shape of dataset\n",
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561ccdd8-4f78-474d-bab5-f192b4a07193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the images\n",
    "fig, ax = plt.subplots(ncols=5, nrows=3, figsize=(12,6))\n",
    "ax = np.ravel(ax)\n",
    "\n",
    "for index in range(15):\n",
    "    ax[index].imshow(images[index][0], cmap=\"gray\")\n",
    "    label = labels[index]\n",
    "    ax[index].set_title(f\"Label: {label}\")\n",
    "    ax[index].set_xticks([])\n",
    "    ax[index].set_yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a916a2-4a3d-46dc-98d8-bc5fec995af8",
   "metadata": {},
   "source": [
    "# 3. Build Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e1ef93-829d-403a-904b-dfe70d3c8d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use one hidden layer and one output layer \n",
    "# Use ReLU activation function to add non-linearity \n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(784, 512)   # 1 * 28 * 28 = 784\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28 * 28)   # flatten the input images\n",
    "        out = self.relu(self.fc1(x))\n",
    "        out = self.fc2(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "model = Network()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c695c185-1037-45f5-a795-072d26d43d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "# check the network information\n",
    "summary(model, input_size=(batch_size, 1, 28, 28), device=\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ad826f-564a-4a49-ad17-82922e060866",
   "metadata": {},
   "source": [
    "## 4. Training and Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f28e28-ca67-4cbd-be53-2414bd47c265",
   "metadata": {},
   "source": [
    "### Check GPU state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bab7e65-12d2-406b-b922-4673df92beb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57755e96-da2f-4a0e-b63a-48083d02090f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386c4b43-5af5-4b83-a326-7188023e109a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065bf8cf-aed5-4138-8035-c4e2616cd3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204901ee-0308-4517-b70b-a86b077d7f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc47d5f-4dae-4572-a11d-9066de17cb07",
   "metadata": {},
   "source": [
    "### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5764d5-9f6f-4eef-b2ce-8170dc1c6fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beec265f-cc24-4ceb-b832-10d9d8cb2a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75703ce8-19b5-4247-99ea-f03631676c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "# set up an optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "# define the loss\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5ba35d-1858-4767-8de6-390b715a933b",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# set the number of epochs\n",
    "n_epochs = 50\n",
    "\n",
    "# lists to record the loss and accuracy\n",
    "train_loss_history = []\n",
    "val_loss_history = []\n",
    "accuracy_history = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "\n",
    "    train_loss = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for images, labels in trainloader:\n",
    "\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # zero the gradients on each training pass\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # make a forward pass through the network\n",
    "        logits = model.forward(images)\n",
    "\n",
    "        # use the network output to calculate the loss (output vs. ground truth)\n",
    "        loss = criterion(logits, labels)\n",
    "\n",
    "        # make a backward pass through the network to calculate the gradients (backpropagation)\n",
    "        loss.backward()\n",
    "\n",
    "        # update the weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # keep track of the loss per epoch\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    else:\n",
    "\n",
    "        # calculate the loss of trainset and record\n",
    "        train_loss = train_loss / len(trainloader)\n",
    "        train_loss_history.append(train_loss)\n",
    "\n",
    "        val_loss = 0\n",
    "        accuracy = 0\n",
    "\n",
    "        # validation start\n",
    "        with torch.no_grad():\n",
    "\n",
    "            # set model as evaluation mode\n",
    "            model.eval()\n",
    "\n",
    "            for images, labels in valloader:\n",
    "\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "                logits = model.forward(images)\n",
    "\n",
    "                loss = criterion(logits, labels)\n",
    "\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                probabilities = logits.softmax(dim=1)\n",
    "\n",
    "                # get only one class with the highest probability\n",
    "                top_probs, top_classes = probabilities.topk(k=1, dim=1)\n",
    "\n",
    "                # find the corrects values\n",
    "                corrects = (top_classes == labels.view(*top_classes.shape))\n",
    "                accuracy += torch.mean(corrects.type(torch.FloatTensor))\n",
    "\n",
    "        # calulate the validation loss and record\n",
    "        val_loss = val_loss / len(valloader)\n",
    "        val_loss_history.append(val_loss)\n",
    "\n",
    "        # calculate the validation accuracy and record\n",
    "        accuracy = accuracy / len(valloader)\n",
    "        accuracy_history.append(accuracy)\n",
    "\n",
    "        # print the current state\n",
    "        metrics = f\"Epoch: {epoch + 1:02}/{n_epochs:02}\"\n",
    "        metrics += \" | \"\n",
    "        metrics += f\"Train loss: {train_loss:.3f}\"\n",
    "        metrics += \" | \"\n",
    "        metrics += f\"Validation loss: {val_loss:.3f}\"\n",
    "        metrics += \" | \"\n",
    "        metrics += f\"Accuracy: {accuracy:.3f}\"\n",
    "        print(metrics)\n",
    "\n",
    "print(\"Elapsed: {0:.2f} seconds\".format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84cff985-9ad8-4eb0-bfa1-81a8cfb11ca2",
   "metadata": {},
   "source": [
    "# 5. Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce64b7b3-6e4f-49bd-bec4-771c2409ecae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the result matrix (loss of trainset and valset)\n",
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "\n",
    "ax.plot(train_loss_history, label=\"Train Loss\")\n",
    "ax.plot(val_loss_history, label=\"Validation Loss\")\n",
    "\n",
    "ax.set_xlabel(\"epoch\")\n",
    "ax.set_ylabel(\"loss\")\n",
    "ax.set_title(\"Train Loss & Validation Loss\")\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1953009a-a571-4bb8-aa25-2ac72ef19717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the result matrix (accuracy of valset)\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(accuracy_history, label=\"Accuracy\")\n",
    "\n",
    "ax.set_xlabel(\"epoch\")\n",
    "ax.set_ylabel(\"accuracy\")\n",
    "ax.set_title(\"Accuracy\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc0bd8e-66d4-443d-a7d0-7f3e8c26d89a",
   "metadata": {},
   "source": [
    "# 6. Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33451ec3-9c56-414c-ab8d-75e372cde9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model named \"model_state_dict.pth\"\n",
    "torch.save(model.state_dict(), \"model_state_dict.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf99b2a-411f-4000-a81c-7273243741b5",
   "metadata": {},
   "source": [
    "# 7. Test the model with Training set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d2b918-d7eb-4777-8e7f-e1bc716a957a",
   "metadata": {},
   "source": [
    "## 7-1. Load the Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30eda05-c2c7-4ca1-b0d5-cc267d117229",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the testset\n",
    "testset = datasets.MNIST('.', download=True, train=False, transform=transform)\n",
    "\n",
    "# loader for the testset\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66417a3-3b16-4a40-b489-f56aaa26f1ed",
   "metadata": {},
   "source": [
    "## 7-2. Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5328c31-315e-494d-8f87-f4560f256dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "total = 0  # stores the total number of testset\n",
    "total_corrects = 0  # stores the total number the model predict correctly\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    for images, labels in testloader:\n",
    "\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        logits = model.forward(images)\n",
    "\n",
    "        probabilities = logits.softmax(dim=1)\n",
    "\n",
    "        top_probs, top_classes = probabilities.topk(k=1, dim=1)\n",
    "        corrects = (top_classes == labels.view(*top_classes.shape))\n",
    "        corrects = int(torch.sum(corrects).cpu().numpy())\n",
    "        total_corrects += corrects\n",
    "\n",
    "        total += labels.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b85c199-4464-42d4-bb7d-9eec4f2f67e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the test accuracy (%)\n",
    "test_accuracy = total_corrects / total * 100.0\n",
    "print(test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55051073-0204-4324-8b62-87a1e6dfc2f9",
   "metadata": {},
   "source": [
    "# 8. 손글씨 inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c404dcc9-007d-4fda-9c74-d4cea91201ac",
   "metadata": {},
   "source": [
    "## 8-1. inference를 위한 transform 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5794cbb8-c28f-4283-93a4-82dc7b6d69a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert image to grayscale image\n",
    "# resize the image to 28 * 28 image\n",
    "# convert image to tensor image\n",
    "inf_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Grayscale(num_output_channels=1),\n",
    "        transforms.Resize((28, 28)),\n",
    "        transforms.ToTensor(),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4bcff3d-4675-4406-9413-aba43b9051dc",
   "metadata": {},
   "source": [
    "## 8-2. 이미지 가져오기 & Inference 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a2ed42-9464-4a1e-b1c2-62c2705c4618",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "# set the folder's path\n",
    "folder_path = \"./images\"\n",
    "\n",
    "# get the name of image files as list\n",
    "image_names = [file for file in os.listdir(folder_path) if file.endswith(('jpg', 'png'))]\n",
    "\n",
    "# get the labels of inputs\n",
    "inference_labels = [int(file.split('_')[0]) for file in image_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b612ea-7651-4a41-9772-032962eb090f",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_images = []\n",
    "correct_probs = []\n",
    "incorrect_images = []\n",
    "incorrect_pred_labels = []\n",
    "incorrect_actual_labels = []\n",
    "\n",
    "# create the input tensor list\n",
    "for image_name, label in zip(image_names, inference_labels):\n",
    "    image = Image.open(os.path.join(folder_path, image_name))\n",
    "    input_image = inf_transform(image).unsqueeze(0)\n",
    "\n",
    "    input_image = input_image.to(device)\n",
    "    \n",
    "    output = model.forward(input_image)\n",
    "    \n",
    "    probability = output.softmax(dim=1)\n",
    "\n",
    "    top_prob, top_class = probability.topk(k=1, dim=1)\n",
    "\n",
    "    if top_class == label:\n",
    "        correct_images.append(input_image)\n",
    "        correct_probs.append(top_prob.item())\n",
    "\n",
    "    else:\n",
    "        incorrect_images.append(input_image)\n",
    "        incorrect_pred_labels.append(top_class)\n",
    "        incorrect_actual_labels.append(label)\n",
    "\n",
    "accuracy = len(incorrect_images) / len(image_names) * 100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc8a0d7-78c5-41ec-becd-055e63d8bcc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2074630-161a-4c03-ad0b-4958dad4827b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49937d23-2ff9-4b4d-8bf9-8dbfcf86e6fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e63c5bc-3700-40b7-bfa0-874a828369ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the images\n",
    "fig, ax = plt.subplots(ncols=3, nrows=3, figsize=(12,6))\n",
    "ax = np.ravel(ax)\n",
    "\n",
    "for index in range(9):\n",
    "    ax[index].imshow(incorrect_images[index].squeeze(0).squeeze(0).cpu().numpy(), cmap=\"gray\")\n",
    "    label = incorrect_actual_labels[index]\n",
    "    ax[index].set_title(f\"Label: {label}\")\n",
    "    ax[index].set_xticks([])\n",
    "    ax[index].set_yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3636176e-f26c-4218-987e-b96ef30ba748",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
